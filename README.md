This is the code for average policy successor feature APSF. The base code has been adopted from https://github.com/ShangtongZhang/DeepRL. 

Run `examples2.py` to train an APSF agent on gridworld (with eps=1 exploration) and use those representations to train a DQN-style agent. 

divine-bush-69: A2C on boxing working
72: A2C on Pong
85: A2C on Minigrid, it nails the task in no time. (rewards: 1)
73, 80: learning using psi(s) and phi(s) representations respectively. (rewards: 1) 
